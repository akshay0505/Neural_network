{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getcwd()+\"/Neural_data/CIFAR10/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv.append(data_dir+\"train.csv\")\n",
    "sys.argv.append(data_dir+\"param.txt\")\n",
    "sys.argv.append(data_dir+\"weightfile.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(sys.argv[0],header=None)\n",
    "test  = pd.read_csv(data_dir+\"test_X.csv\",header=None)\n",
    "classes = pd.get_dummies(train[1024],prefix=\"class_\")\n",
    "train = pd.concat([train.iloc[:,:-1],classes],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialiseWeights(layer):\n",
    "    weights = []\n",
    "    bias = []\n",
    "    for i in range(1,len(layer)):\n",
    "        weights.append(np.zeros(layer[i-1]*layer[i]).reshape(layer[i],layer[i-1]))\n",
    "        bias.append(np.zeros(layer[i]).reshape(layer[i],1))\n",
    "#         print(weights[i-1].shape,bias[i-1].shape)\n",
    "    return (weights,bias)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[:,-10:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 1024) (20000, 10)\n",
      "2 0.5 1000 100 [1024, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "X_train = train.iloc[:,:-10].values\n",
    "Y_train = train.iloc[:,-10:].values\n",
    "print(X_train.shape,Y_train.shape)\n",
    "with open(sys.argv[1]) as f:\n",
    "    param = f.read().split(\"\\n\")\n",
    "    learningType = int(param[0])\n",
    "    learningRate = float(param[1])\n",
    "    maxIteration = int(param[2])\n",
    "    batchSize = int(param[3])\n",
    "    layer = list(map(int,param[4].split(\" \")))\n",
    "    layer.insert(0,X_train.shape[1])\n",
    "    layer.append(Y_train.shape[1])\n",
    "print(learningType,learningRate,maxIteration,batchSize,layer)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    z = np.exp(z)\n",
    "    return z/np.sum(z,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(weights,bias,X_train):\n",
    "    a_layer = []\n",
    "    z_layer = []\n",
    "    a_layer.append(X_train.T)\n",
    "    z_layer.append(0)\n",
    "    for i in range(0,len(layer)-2):\n",
    "        z_layer.append(np.matmul(weights[i],a_layer[i])+bias[i])\n",
    "        a_layer.append(sigmoid(z_layer[i+1]))\n",
    "    z_layer.append(np.matmul(weights[-1],a_layer[-1])+bias[-1])\n",
    "    a_layer.append(softmax(z_layer[-1]))    \n",
    "    return (a_layer,z_layer)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagate(weights,bias,a_layer,z_layer,X_train,Y_train,iteration):\n",
    "    new_weights = []\n",
    "    new_bias = []\n",
    "    layer_index = len(a_layer)-1\n",
    "    delta = (a_layer[-1]-Y_train.T)/Y_train.shape[0]\n",
    "    new_weights.append(np.subtract(weights[layer_index-1] ,np.multiply((learningRate/iteration),np.matmul(delta,a_layer[layer_index-1].T))))\n",
    "    b = np.sum(delta,axis=1)\n",
    "    new_bias.append(np.subtract(bias[layer_index-1],np.multiply((learningRate/iteration),b.reshape(b.shape[0],1))))\n",
    "    layer_index-=1\n",
    "    while(layer_index>0):\n",
    "        s = sigmoid(z_layer[layer_index])\n",
    "        sigmaDer = (s*(1-s))\n",
    "        delta = np.matmul(weights[layer_index].T,delta)*sigmaDer\n",
    "        new_weights.append(np.subtract(weights[layer_index-1] ,np.multiply((learningRate/iteration),np.matmul(delta,a_layer[layer_index-1].T))))\n",
    "        b = np.sum(delta,axis=1)\n",
    "        new_bias.append(np.subtract(bias[layer_index-1],np.multiply((learningRate/iteration),b.reshape(b.shape[0],1))))\n",
    "        layer_index-=1\n",
    "    new_bias.reverse()\n",
    "    new_weights.reverse()\n",
    "    return (new_weights,new_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we2.txt\n",
      "we11.txt\n",
      "we21.txt\n",
      "we31.txt\n",
      "we41.txt\n"
     ]
    }
   ],
   "source": [
    "k = batchSize\n",
    "l = X_train.shape[0]\n",
    "weights, bias = initialiseWeights(layer)\n",
    "error = []\n",
    "o = maxIteration\n",
    "batches = l/k\n",
    "for i in range(o):\n",
    "    start_index = int(k*(i%batches))\n",
    "    end_index = int(k*((i%batches)+1))\n",
    "    a_layer , z_layer = feedforward(weights,bias,X_train[start_index:end_index,:])\n",
    "    weights, bias = backpropagate(weights,bias,a_layer,z_layer,X_train[start_index:end_index,:],Y_train[start_index:end_index,:],np.sqrt(i+1))\n",
    "    if (i+1 in [1, 10, 20, 30, 40]):\n",
    "        a = np.array([])\n",
    "        for m in range(len(bias)):\n",
    "            a = np.concatenate((a,bias[m].flatten(),weights[m].flatten('F')))\n",
    "        print(\"we\"+str(i+2)+\".txt\")\n",
    "        np.savetxt(\"we\"+str(i+2)+\".txt\",a)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([])\n",
    "for i in range(len(bias)):\n",
    "    a = np.concatenate((a,bias[i].flatten(),weights[i].flatten('F')))\n",
    "np.savetxt(\"we1.txt\",a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_layer[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_der = -Y_train.T/(a_layer[-1]*Y_train.shape[0])\n",
    "error_der.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = softmax(z_layer[-1])\n",
    "(s*(1-s)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_laye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_layer[2][a_layer[2]>0.5]=1\n",
    "a_layer[2][a_layer[2]<0.5]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_layer[2].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'pred':a_layer[2].tolist(),'actual':Y_train.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(a_layer[2],Y_train,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagate(weights,bias,a_layer,z_layer,X_train,Y_train):\n",
    "    new_weights = []\n",
    "    new_bias = []\n",
    "    error_der = (a_layer[2]-Y_train)/((1-a_layer[2])*a_layer[2]*X_train.shape[0])\n",
    "    s = sigmoid(z_layer[2])\n",
    "    sigmaDer = (s*(1-s))\n",
    "    deltaL = error_der*sigmaDer\n",
    "    new_weights.append(np.subtract(weights[1] ,np.multiply(learningRate,np.matmul(deltaL,a_layer[1].T))))\n",
    "    b = np.sum(deltaL,axis=1)\n",
    "    new_bias.append(np.subtract(bias[1],np.multiply(learningRate,b.reshape(b.shape[0],1))))\n",
    "    s = sigmoid(z_layer[1])\n",
    "    sigmaDer = (s*(1-s))\n",
    "    deltal3 = np.matmul(weights[1].T,deltaL)*sigmaDer\n",
    "    new_weights.append(np.subtract(weights[0] ,np.multiply(learningRate,np.matmul(deltal3,a_layer[0].T))))\n",
    "    b = np.sum(deltal3,axis=1)\n",
    "    new_bias.append(np.subtract(bias[0],np.multiply(learningRate,b.reshape(b.shape[0],1))))\n",
    "    new_bias.reverse()\n",
    "    new_weights.reverse()\n",
    "    return (new_weights,new_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k = batchSize\n",
    "l = X_train.shape[0]\n",
    "maxIteration =30\n",
    "weights, bias = initialiseWeights(layer)\n",
    "error = []\n",
    "for i in range(maxIteration):\n",
    "    start_index = int((k)*(i%6))\n",
    "    end_index = int((k)*((i%6)+1))\n",
    "    a_layer , z_layer = feedforward(weights,bias,X_train[start_index:end_index,:])\n",
    "    weights, bias = backpropagate(weights,bias,a_layer,z_layer,X_train[start_index:end_index,:],Y_train[start_index:end_index])\n",
    "# a_layer , z_layer = feedforward(weights,bias,X_train)\n",
    "# error.append(np.linalg.norm(np.subtract(a_layer[2],Y_train))/300)   \n",
    "for i in range(len(bias)):\n",
    "    print(bias[i].flatten())\n",
    "print(\"errr\")\n",
    "for i in range(len(weights)):\n",
    "    print(weights[i].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_layer , z_layer = feedforward(weights,bias,X_train[0:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights = []\n",
    "new_bias = []\n",
    "# error_der = (a_layer[2]-Y_train)/((1-a_layer[2])*a_layer[2]*X_train.shape[0])\n",
    "# s = sigmoid(z_layer[2])\n",
    "# sigmaDer = (s*(1-s))\n",
    "# deltaL = error_der*sigmaDer\n",
    "error_der = a_layer\n",
    "# print(deltaL.shape)\n",
    "# new_weights.append(np.subtract(weights[1] ,np.multiply(learningRate,np.matmul(deltaL,a_layer[1].T))))\n",
    "# b = np.sum(deltaL,axis=1)\n",
    "# new_bias.append(b.reshape(b.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, bias = initialiseWeights(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "k = batchSize\n",
    "l = X_train.shape[0]\n",
    "maxIteration =1\n",
    "weights, bias = initialiseWeights(layer)\n",
    "error = []\n",
    "for j in range(maxIteration):\n",
    "#     print(j,end=\"\\r\",flush=True)\n",
    "    for i in range(int(l/k)):\n",
    "        start_index = int((k)*i)\n",
    "        end_index = int((k)*(i+1))\n",
    "        a_layer , z_layer = feedforward(weights,bias,X_train[start_index:end_index,:])\n",
    "        weights, bias = backpropagate(weights,bias,a_layer,z_layer,X_train[start_index:end_index,:],Y_train[start_index:end_index])\n",
    "#         for k in range(len(bias)):\n",
    "#             print(bias[k].flatten(),weights[k].flatten())\n",
    "#         print(\"hi this is akshay\\n\\n\\n\")\n",
    "    a_layer , z_layer = feedforward(weights,bias,X_train)\n",
    "    error.append(np.linalg.norm(np.subtract(a_layer[2],Y_train))/300)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(error)),error)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_layer , z_layer = feedforward(weights,bias,X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_layer[2]+Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, bias = initialiseWeights(layer)\n",
    "a_layer , z_layer = feedforward(weights,bias,X_train[0:50])\n",
    "weights, bias = backpropagate(weights,bias,a_layer,z_layer,X_train[0:50],Y_train[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(bias)):\n",
    "    print(bias[i].flatten())\n",
    "print(\"errr\")\n",
    "for i in range(len(weights)):\n",
    "    print(weights[i].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am = [10 , 20 ,30]\n",
    "40 in am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights = []\n",
    "new_bias = []\n",
    "error_der = (a_layer[2]-Y_train)/((1-a_layer[2])*a_layer[2]*X_train.shape[0])\n",
    "s = sigmoid(z_layer[2])\n",
    "sigmaDer = (s*(1-s))\n",
    "deltaL = error_der*sigmaDer\n",
    "print(deltaL.shape)\n",
    "new_weights.append(np.subtract(weights[1] ,np.multiply(learningRate,np.matmul(deltaL,a_layer[1].T))))\n",
    "b = np.sum(deltaL,axis=1)\n",
    "new_bias.append(b.reshape(b.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(new_weights[-1])\n",
    "s = sigmoid(z_layer[1])\n",
    "sigmaDer = (s*(1-s))\n",
    "deltal3 = np.matmul(weights[1].T,deltaL)*sigmaDer\n",
    "new_weights.append(np.subtract(weights[0] ,np.multiply(learningRate,np.matmul(deltal3,a_layer[0].T))))\n",
    "b = np.sum(deltal3,axis=1)\n",
    "new_bias.append(b.reshape(b.shape[0],1))\n",
    "# print(new_weights[0].shape,new_weights[1].shape)\n",
    "# print(np.sum(deltaL),deltal3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bias.reverse()\n",
    "new_weights.reverse()\n",
    "print(new_bias,\"\\n\",new_weights)\n",
    "weights = new_weights\n",
    "bias = new_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sigmoid(z_layer[1])\n",
    "sigmaDer = (s*(1-s))\n",
    "deltal3 = np.matmul(weights[1].T,deltaL)*sigmaDer\n",
    "print(weights[1].shape,deltaL.shape,sigmaDer.shape)\n",
    "new_bias.append(np.sum(deltal3,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matmul(weights[1].T,deltaL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights = []\n",
    "new_bias = []\n",
    "error_der = (a_layer[4]-Y_train)/((1-a_layer[4])*a_layer[4]*X_train.shape[0])\n",
    "s = sigmoid(z_layer[4])\n",
    "sigmaDer = (s*(1-s))\n",
    "deltaL = error_der*sigmaDer\n",
    "print(deltaL.shape)\n",
    "new_weights.append(np.subtract(weights[3] ,np.multiply(learningRate,np.matmul(deltaL,a_layer[3].T))))\n",
    "print(new_weights[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sigmoid(z_layer[3])\n",
    "sigmaDer = (s*(1-s))\n",
    "deltal3 = np.matmul(weights[3].T,deltaL)*sigmaDer\n",
    "new_weights.append(np.subtract(weights[2] ,np.multiply(learningRate,np.matmul(deltal3,a_layer[2].T))))\n",
    "print(new_weights[-1])\n",
    "# print(weights[2].shape,deltal3.shape,a_layer[2].T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sigmoid(z_layer[2])\n",
    "sigmaDer = (s*(1-s))\n",
    "deltal2 = np.matmul(weights[2].T,deltal3)*sigmaDer\n",
    "new_weights.append(np.subtract(weights[1] ,np.multiply(learningRate,np.matmul(deltal2,a_layer[1].T))))\n",
    "print(new_weights[-1])\n",
    "# print(weights[2].shape,deltal3.shape,a_layer[2].T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sigmoid(z_layer[1])\n",
    "sigmaDer = (s*(1-s))\n",
    "deltal1 = np.matmul(weights[1].T,deltal2)*sigmaDer\n",
    "new_weights.append(np.subtract(weights[0] ,np.multiply(learningRate,np.matmul(deltal1,a_layer[0].T))))\n",
    "print(new_weights[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltal3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.negative(deltaL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = X_train.T\n",
    "z1 = np.matmul(weights[0],y0)+bias[0]\n",
    "y1 = sigmoid(z1)\n",
    "z2 = np.matmul(weights[1],y1)+bias[1]\n",
    "y2 = sigmoid(z2)\n",
    "z3 = np.matmul(weights[2],y2)+bias[2]\n",
    "y3 = sigmoid(z3)\n",
    "z4 = np.matmul(weights[3],y3)+bias[3]\n",
    "y4 = sigmoid(z4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y0.shape,y1.shape,y2.shape,y3.shape,y4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
