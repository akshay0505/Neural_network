{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getcwd()+\"/Neural_data/CIFAR10/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv.append(data_dir+\"train.csv\")\n",
    "sys.argv.append(data_dir+\"test_X.csv\")\n",
    "sys.argv.append(data_dir+\"weightfile.txt\")\n",
    "sys.argv.append(data_dir+\"param.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(sys.argv[0],header=None)\n",
    "test  = pd.read_csv(sys.argv[1],header=None)\n",
    "train_class = train.iloc[:,-1].values\n",
    "classes = pd.get_dummies(train[1024],prefix=\"class_\")\n",
    "train = pd.concat([train.iloc[:,:-1],classes],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialiseWeights(layer):\n",
    "    weights = []\n",
    "    bias = []\n",
    "    for i in range(1,len(layer)):\n",
    "        weights.append((np.random.rand(layer[i-1]*layer[i]).reshape(layer[i],layer[i-1])-0.5))\n",
    "        bias.append((np.random.rand(layer[i]).reshape(layer[i],1)-0.5))\n",
    "    return (weights,bias)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliseFeatures(X_train):\n",
    "    return (X_train-np.mean(X_train,axis=0))/255;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp((-1)*z))\n",
    "def sigmoid_der(z):\n",
    "    s = sigmoid(z)\n",
    "    return s*(1-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(z):\n",
    "    return (2/(1+np.exp((-2)*z)))-1\n",
    "def tanhder(z):\n",
    "    t = tanh(z)\n",
    "    return 1-t*t;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    return np.where(z>0,z,0)\n",
    "def reluder(z):\n",
    "    z[z>0]=1\n",
    "    z[z<0]=0\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    z = np.exp(z)\n",
    "    return z/np.sum(z,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(weights,bias,X_train):\n",
    "    a_layer = []\n",
    "    z_layer = []\n",
    "    a_layer.append(X_train.T)\n",
    "    z_layer.append(0)\n",
    "    for i in range(0,len(layer)-2):\n",
    "        z_layer.append(np.matmul(weights[i],a_layer[i])+bias[i])\n",
    "#         a_layer.append(sigmoid(z_layer[i+1]))\n",
    "        a_layer.append(relu(z_layer[i+1]))\n",
    "#         a_layer.append(tanh(z_layer[i+1]))\n",
    "    z_layer.append(np.matmul(weights[-1],a_layer[-1])+bias[-1])\n",
    "    a_layer.append(softmax(z_layer[-1]))    \n",
    "    return (a_layer,z_layer)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagate(weights,bias,a_layer,z_layer,X_train,Y_train,iteration):\n",
    "    new_weights = []\n",
    "    new_bias = []\n",
    "    layer_index = len(a_layer)-1\n",
    "    delta = (a_layer[-1]-Y_train.T)/Y_train.shape[0]\n",
    "    new_weights.append(np.subtract(weights[layer_index-1] ,np.multiply((learningRate/iteration),np.matmul(delta,a_layer[layer_index-1].T))))\n",
    "    b = np.sum(delta,axis=1)\n",
    "    new_bias.append(np.subtract(bias[layer_index-1],np.multiply((learningRate/iteration),b.reshape(b.shape[0],1))))\n",
    "    layer_index-=1\n",
    "    while(layer_index>0):\n",
    "#         delta = np.matmul(weights[layer_index].T,delta)*sigmoid_der(z_layer[layer_index])\n",
    "        delta = np.matmul(weights[layer_index].T,delta)*reluder(z_layer[layer_index])\n",
    "#         delta = np.matmul(weights[layer_index].T,delta)*tanhder(z_layer[layer_index])\n",
    "        new_weights.append(np.subtract(weights[layer_index-1] ,np.multiply((learningRate/iteration),np.matmul(delta,a_layer[layer_index-1].T))))\n",
    "        b = np.sum(delta,axis=1)\n",
    "        new_bias.append(np.subtract(bias[layer_index-1],np.multiply((learningRate/iteration),b.reshape(b.shape[0],1))))\n",
    "        layer_index-=1\n",
    "    new_bias.reverse()\n",
    "    new_weights.reverse()\n",
    "    return (new_weights,new_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(Y_pred,Y_actual):\n",
    "    return (-1)*np.sum(Y_actual.T*np.log(Y_pred))/Y_pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hot_encode(Y_pred,Y_actual):\n",
    "    Y_pred = Y_pred.T  \n",
    "    Y_actual = Y_actual.T\n",
    "    maxVal = np.max(Y_pred,axis=1).reshape(Y_pred.shape[0],1) \n",
    "    Y_pred = Y_pred-maxVal\n",
    "    Y_pred[Y_pred==0]=1\n",
    "    Y_pred[Y_pred<0]=0\n",
    "    d = np.sum(Y_pred*Y_actual)\n",
    "    return d/Y_actual.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1025)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 1024) (20000, 10)\n",
      "2 0.03 20000 100 [1024, 400, 10]\n"
     ]
    }
   ],
   "source": [
    "X_train = normaliseFeatures(train.iloc[:-2000,:-10].values)\n",
    "Y_train = train.iloc[:,-10:].values\n",
    "X_test = normaliseFeatures(train.iloc[-2000:,:-10].values)\n",
    "Y_test = train.iloc[-2000:,-10:].values\n",
    "print(X_train.shape,Y_train.shape)\n",
    "with open(sys.argv[3]) as f:\n",
    "    param = f.read().split(\"\\n\")\n",
    "    learningType = int(param[0])\n",
    "    learningRate = float(param[1])\n",
    "    maxIteration = int(param[2])\n",
    "    batchSize = int(param[3])\n",
    "    layer = list(map(int,param[4].split(\" \")))\n",
    "    layer.insert(0,X_train.shape[1])\n",
    "    layer.append(Y_train.shape[1])\n",
    "# learningType = 2\n",
    "# learningRate = float(0.5)\n",
    "# maxIteration = int(1000)\n",
    "# batchSize = int(100)\n",
    "# layer = [300 , 150, 90]\n",
    "# layer.insert(0,X_train.shape[1])\n",
    "# layer.append(Y_train.shape[1])\n",
    "print(learningType,learningRate,maxIteration,batchSize,layer)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-3452a7811b8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mend_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0ma_layer\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mz_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeedforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mY_pred\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeedforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhot_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0merror_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_layer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-0f68475d23ae>\u001b[0m in \u001b[0;36mfeedforward\u001b[0;34m(weights, bias, X_train)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mz_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mz_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma_layer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#         a_layer.append(sigmoid(z_layer[i+1]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0ma_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_layer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k = batchSize\n",
    "l = X_train.shape[0]\n",
    "weights, bias = initialiseWeights(layer)\n",
    "error_value = []\n",
    "o = maxIteration\n",
    "batches = l/k\n",
    "accuracy_test = []\n",
    "accuracy_train = []\n",
    "for i in range(o):\n",
    "    start_index = int(k*(i%batches))\n",
    "    end_index = int(k*((i%batches)+1))\n",
    "    a_layer , z_layer = feedforward(weights,bias,X_train[start_index:end_index,:])\n",
    "    Y_pred , z = feedforward(weights,bias,X_test)\n",
    "    accuracy.append(hot_encode(Y_pred[-1],Y_test.T))\n",
    "    error_value.append(error(a_layer[-1],Y_train[start_index:end_index,:]))\n",
    "    weights, bias = backpropagate(weights,bias,a_layer,z_layer,X_train[start_index:end_index,:],Y_train[start_index:end_index,:],np.sqrt(1))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(accuracy)),accuracy)\n",
    "plt.show\n",
    "# plt.plot(range(len(error_value)),error_value)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.281"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_layer , z_layer = feedforward(weights,bias,X_test)\n",
    "hot_encode(a_layer[-1],Y_test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.3939549 , -0.36258235,  0.0060451 , ...,  0.19820196,\n",
       "          0.03349608,  0.13545686],\n",
       "        [-0.38130588, -0.3420902 ,  0.00300784, ...,  0.20300784,\n",
       "          0.02261569,  0.13241961],\n",
       "        [-0.36989608, -0.33068039,  0.00657451, ...,  0.20657451,\n",
       "          0.02226078,  0.13598627],\n",
       "        ...,\n",
       "        [-0.39805686, -0.13923333, -0.28433137, ...,  0.1195902 ,\n",
       "         -0.11570392, -0.33923333],\n",
       "        [-0.39736078, -0.2208902 , -0.27971373, ...,  0.11244314,\n",
       "         -0.11500784, -0.36598824],\n",
       "        [-0.39674118, -0.3065451 , -0.27909412, ...,  0.11698431,\n",
       "         -0.1183098 , -0.40850588]]),\n",
       " array([[4.15432036, 2.84479519, 0.68705433, ..., 0.        , 3.12904423,\n",
       "         4.09157835],\n",
       "        [1.53789541, 2.21018845, 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [1.51333312, 0.        , 0.        , ..., 0.75488497, 0.        ,\n",
       "         0.16283053],\n",
       "        ...,\n",
       "        [0.        , 0.        , 1.08502337, ..., 1.70942646, 2.35456211,\n",
       "         0.        ],\n",
       "        [0.        , 1.98673225, 0.        , ..., 4.57605751, 0.        ,\n",
       "         1.84461447],\n",
       "        [1.15690157, 1.19893302, 0.50314745, ..., 0.        , 0.        ,\n",
       "         1.5764483 ]]),\n",
       " array([[0.13318283, 0.01779208, 0.11298698, ..., 0.08591911, 0.07902122,\n",
       "         0.03328473],\n",
       "        [0.06959333, 0.00838921, 0.03542503, ..., 0.36316722, 0.00088935,\n",
       "         0.47578327],\n",
       "        [0.20512747, 0.21252562, 0.03749422, ..., 0.09414576, 0.01999981,\n",
       "         0.00638797],\n",
       "        ...,\n",
       "        [0.0129039 , 0.08355511, 0.0964438 , ..., 0.12416949, 0.00734389,\n",
       "         0.02534702],\n",
       "        [0.07819798, 0.00222248, 0.42549903, ..., 0.04232239, 0.0712433 ,\n",
       "         0.27865183],\n",
       "        [0.04035683, 0.0014053 , 0.08609693, ..., 0.06141184, 0.01383393,\n",
       "         0.06853996]])]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_layer , z_layer = feedforward(weights,bias,X_test)\n",
    "\n",
    "# a = np.array([ np.where(out==np.amax(out))[0][0] for out in a_layer[-1].T])\n",
    "# j=0\n",
    "# for i in range(a.shape[0]):\n",
    "#     if(a[i]==train_class[i+18000]):\n",
    "#         j+=1\n",
    "# print(j/a.shape[0])\n",
    "# plt.hist(a)\n",
    "# plt.show()\n",
    "# plt.plot(range(len(error_value)),error_value)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_layer , z_layer = feedforward(weights,bias,X_test)\n",
    "a = np.array([ np.where(out==np.amax(out))[0][0] for out in a_layer[-1].T])\n",
    "j=0\n",
    "for i in range(a.shape[0]):\n",
    "    if(a[i]==train_class[i]):\n",
    "        j+=1\n",
    "print(j/a.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_layer , z_layer = feedforward(weights,bias,X_train)\n",
    "a = np.array([ np.where(out==np.amax(out))[0][0]+1 for out in a_layer[-1].T])\n",
    "j=0\n",
    "for i in range(a.shape[0]):\n",
    "    if(a[i]==train_class[i]):\n",
    "        j+=1\n",
    "j/a.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(error_value)),error_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([])\n",
    "for m in range(len(bias)):\n",
    "    a = np.concatenate((a,bias[m].flatten(),weights[m].flatten('F')))\n",
    "np.savetxt(\"weigth.txt\",a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_layer[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_der = -Y_train.T/(a_layer[-1]*Y_train.shape[0])\n",
    "error_der.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = softmax(z_layer[-1])\n",
    "(s*(1-s)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_laye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_layer[2][a_layer[2]>0.5]=1\n",
    "a_layer[2][a_layer[2]<0.5]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_layer[2].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'pred':a_layer[2].tolist(),'actual':Y_train.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(a_layer[2],Y_train,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagate(weights,bias,a_layer,z_layer,X_train,Y_train):\n",
    "    new_weights = []\n",
    "    new_bias = []\n",
    "    error_der = (a_layer[2]-Y_train)/((1-a_layer[2])*a_layer[2]*X_train.shape[0])\n",
    "    s = sigmoid(z_layer[2])\n",
    "    sigmaDer = (s*(1-s))\n",
    "    deltaL = error_der*sigmaDer\n",
    "    new_weights.append(np.subtract(weights[1] ,np.multiply(learningRate,np.matmul(deltaL,a_layer[1].T))))\n",
    "    b = np.sum(deltaL,axis=1)\n",
    "    new_bias.append(np.subtract(bias[1],np.multiply(learningRate,b.reshape(b.shape[0],1))))\n",
    "    s = sigmoid(z_layer[1])\n",
    "    sigmaDer = (s*(1-s))\n",
    "    deltal3 = np.matmul(weights[1].T,deltaL)*sigmaDer\n",
    "    new_weights.append(np.subtract(weights[0] ,np.multiply(learningRate,np.matmul(deltal3,a_layer[0].T))))\n",
    "    b = np.sum(deltal3,axis=1)\n",
    "    new_bias.append(np.subtract(bias[0],np.multiply(learningRate,b.reshape(b.shape[0],1))))\n",
    "    new_bias.reverse()\n",
    "    new_weights.reverse()\n",
    "    return (new_weights,new_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k = batchSize\n",
    "l = X_train.shape[0]\n",
    "maxIteration =30\n",
    "weights, bias = initialiseWeights(layer)\n",
    "error = []\n",
    "for i in range(maxIteration):\n",
    "    start_index = int((k)*(i%6))\n",
    "    end_index = int((k)*((i%6)+1))\n",
    "    a_layer , z_layer = feedforward(weights,bias,X_train[start_index:end_index,:])\n",
    "    weights, bias = backpropagate(weights,bias,a_layer,z_layer,X_train[start_index:end_index,:],Y_train[start_index:end_index])\n",
    "# a_layer , z_layer = feedforward(weights,bias,X_train)\n",
    "# error.append(np.linalg.norm(np.subtract(a_layer[2],Y_train))/300)   \n",
    "for i in range(len(bias)):\n",
    "    print(bias[i].flatten())\n",
    "print(\"errr\")\n",
    "for i in range(len(weights)):\n",
    "    print(weights[i].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_layer , z_layer = feedforward(weights,bias,X_train[0:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights = []\n",
    "new_bias = []\n",
    "# error_der = (a_layer[2]-Y_train)/((1-a_layer[2])*a_layer[2]*X_train.shape[0])\n",
    "# s = sigmoid(z_layer[2])\n",
    "# sigmaDer = (s*(1-s))\n",
    "# deltaL = error_der*sigmaDer\n",
    "error_der = a_layer\n",
    "# print(deltaL.shape)\n",
    "# new_weights.append(np.subtract(weights[1] ,np.multiply(learningRate,np.matmul(deltaL,a_layer[1].T))))\n",
    "# b = np.sum(deltaL,axis=1)\n",
    "# new_bias.append(b.reshape(b.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, bias = initialiseWeights(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "k = batchSize\n",
    "l = X_train.shape[0]\n",
    "maxIteration =1\n",
    "weights, bias = initialiseWeights(layer)\n",
    "error = []\n",
    "for j in range(maxIteration):\n",
    "#     print(j,end=\"\\r\",flush=True)\n",
    "    for i in range(int(l/k)):\n",
    "        start_index = int((k)*i)\n",
    "        end_index = int((k)*(i+1))\n",
    "        a_layer , z_layer = feedforward(weights,bias,X_train[start_index:end_index,:])\n",
    "        weights, bias = backpropagate(weights,bias,a_layer,z_layer,X_train[start_index:end_index,:],Y_train[start_index:end_index])\n",
    "#         for k in range(len(bias)):\n",
    "#             print(bias[k].flatten(),weights[k].flatten())\n",
    "#         print(\"hi this is akshay\\n\\n\\n\")\n",
    "    a_layer , z_layer = feedforward(weights,bias,X_train)\n",
    "    error.append(np.linalg.norm(np.subtract(a_layer[2],Y_train))/300)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(error)),error)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_layer , z_layer = feedforward(weights,bias,X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_layer[2]+Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, bias = initialiseWeights(layer)\n",
    "a_layer , z_layer = feedforward(weights,bias,X_train[0:50])\n",
    "weights, bias = backpropagate(weights,bias,a_layer,z_layer,X_train[0:50],Y_train[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(bias)):\n",
    "    print(bias[i].flatten())\n",
    "print(\"errr\")\n",
    "for i in range(len(weights)):\n",
    "    print(weights[i].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am = [10 , 20 ,30]\n",
    "40 in am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights = []\n",
    "new_bias = []\n",
    "error_der = (a_layer[2]-Y_train)/((1-a_layer[2])*a_layer[2]*X_train.shape[0])\n",
    "s = sigmoid(z_layer[2])\n",
    "sigmaDer = (s*(1-s))\n",
    "deltaL = error_der*sigmaDer\n",
    "print(deltaL.shape)\n",
    "new_weights.append(np.subtract(weights[1] ,np.multiply(learningRate,np.matmul(deltaL,a_layer[1].T))))\n",
    "b = np.sum(deltaL,axis=1)\n",
    "new_bias.append(b.reshape(b.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(new_weights[-1])\n",
    "s = sigmoid(z_layer[1])\n",
    "sigmaDer = (s*(1-s))\n",
    "deltal3 = np.matmul(weights[1].T,deltaL)*sigmaDer\n",
    "new_weights.append(np.subtract(weights[0] ,np.multiply(learningRate,np.matmul(deltal3,a_layer[0].T))))\n",
    "b = np.sum(deltal3,axis=1)\n",
    "new_bias.append(b.reshape(b.shape[0],1))\n",
    "# print(new_weights[0].shape,new_weights[1].shape)\n",
    "# print(np.sum(deltaL),deltal3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bias.reverse()\n",
    "new_weights.reverse()\n",
    "print(new_bias,\"\\n\",new_weights)\n",
    "weights = new_weights\n",
    "bias = new_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sigmoid(z_layer[1])\n",
    "sigmaDer = (s*(1-s))\n",
    "deltal3 = np.matmul(weights[1].T,deltaL)*sigmaDer\n",
    "print(weights[1].shape,deltaL.shape,sigmaDer.shape)\n",
    "new_bias.append(np.sum(deltal3,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matmul(weights[1].T,deltaL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights = []\n",
    "new_bias = []\n",
    "error_der = (a_layer[4]-Y_train)/((1-a_layer[4])*a_layer[4]*X_train.shape[0])\n",
    "s = sigmoid(z_layer[4])\n",
    "sigmaDer = (s*(1-s))\n",
    "deltaL = error_der*sigmaDer\n",
    "print(deltaL.shape)\n",
    "new_weights.append(np.subtract(weights[3] ,np.multiply(learningRate,np.matmul(deltaL,a_layer[3].T))))\n",
    "print(new_weights[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sigmoid(z_layer[3])\n",
    "sigmaDer = (s*(1-s))\n",
    "deltal3 = np.matmul(weights[3].T,deltaL)*sigmaDer\n",
    "new_weights.append(np.subtract(weights[2] ,np.multiply(learningRate,np.matmul(deltal3,a_layer[2].T))))\n",
    "print(new_weights[-1])\n",
    "# print(weights[2].shape,deltal3.shape,a_layer[2].T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sigmoid(z_layer[2])\n",
    "sigmaDer = (s*(1-s))\n",
    "deltal2 = np.matmul(weights[2].T,deltal3)*sigmaDer\n",
    "new_weights.append(np.subtract(weights[1] ,np.multiply(learningRate,np.matmul(deltal2,a_layer[1].T))))\n",
    "print(new_weights[-1])\n",
    "# print(weights[2].shape,deltal3.shape,a_layer[2].T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sigmoid(z_layer[1])\n",
    "sigmaDer = (s*(1-s))\n",
    "deltal1 = np.matmul(weights[1].T,deltal2)*sigmaDer\n",
    "new_weights.append(np.subtract(weights[0] ,np.multiply(learningRate,np.matmul(deltal1,a_layer[0].T))))\n",
    "print(new_weights[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltal3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.negative(deltaL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = X_train.T\n",
    "z1 = np.matmul(weights[0],y0)+bias[0]\n",
    "y1 = sigmoid(z1)\n",
    "z2 = np.matmul(weights[1],y1)+bias[1]\n",
    "y2 = sigmoid(z2)\n",
    "z3 = np.matmul(weights[2],y2)+bias[2]\n",
    "y3 = sigmoid(z3)\n",
    "z4 = np.matmul(weights[3],y3)+bias[3]\n",
    "y4 = sigmoid(z4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y0.shape,y1.shape,y2.shape,y3.shape,y4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "train = pd.read_csv(sys.argv[1],header=None)\n",
    "test  = pd.read_csv(sys.argv[2],header=None)\n",
    "classes = pd.get_dummies(train[1024],prefix=\"class_\")\n",
    "train = pd.concat([train.iloc[:,:-1],classes],axis=1)\n",
    "def initialiseWeights(layer):\n",
    "    weights = []\n",
    "    bias = []\n",
    "    for i in range(1,len(layer)):\n",
    "        weights.append((np.random.rand(layer[i-1]*layer[i]).reshape(layer[i],layer[i-1])-0.5))\n",
    "        bias.append((np.random.rand(layer[i]).reshape(layer[i],1)-0.5))\n",
    "    return (weights,bias)    \n",
    "def normaliseFeatures(X_train):\n",
    "    return (X_train-np.mean(X_train,axis=0))/255;\n",
    "X_train = normaliseFeatures(train.iloc[:,:-10].values)\n",
    "Y_train = train.iloc[:,-10:].values\n",
    "X_test  = test.iloc[:,:-1].values\n",
    "print(X_train.shape,Y_train.shape,X_test.shape)\n",
    "learningType = 2\n",
    "learningRate = float(0.01)\n",
    "maxIteration = int(1000)\n",
    "batchSize = int(100)\n",
    "layer = [10]\n",
    "layer.insert(0,X_train.shape[1])\n",
    "layer.append(Y_train.shape[1])\n",
    "print(learningType,learningRate,maxIteration,batchSize,layer)\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp((-1)*z))\n",
    "def sigmoid_der(z):\n",
    "    s = sigmoid(z)\n",
    "    return s*(1-s)\n",
    "def tanh(z):\n",
    "    return (2/(1+np.exp((-2)*z)))-1\n",
    "def tanhder(z):\n",
    "    t = tanh(z)\n",
    "    return 1-t*t;\n",
    "def relu(z):\n",
    "    return np.where(z>0,z,0)\n",
    "def reluder(z):\n",
    "    z[z>0]=1\n",
    "    z[z<0]=0\n",
    "    return z\n",
    "def softmax(z):\n",
    "    z = np.exp(z)\n",
    "    return z/np.sum(z,axis=0)    \n",
    "def feedforward(weights,bias,X_train):\n",
    "    a_layer = []\n",
    "    z_layer = []\n",
    "    a_layer.append(X_train.T)\n",
    "    z_layer.append(0)\n",
    "    for i in range(0,len(layer)-2):\n",
    "        z_layer.append(np.matmul(weights[i],a_layer[i])+bias[i])\n",
    "#         a_layer.append(sigmoid(z_layer[i+1]))\n",
    "        a_layer.append(relu(z_layer[i+1]))\n",
    "#         a_layer.append(tanh(z_layer[i+1]))\n",
    "    z_layer.append(np.matmul(weights[-1],a_layer[-1])+bias[-1])\n",
    "    a_layer.append(softmax(z_layer[-1]))    \n",
    "    return (a_layer,z_layer)    \n",
    "def backpropagate(weights,bias,a_layer,z_layer,X_train,Y_train,iteration):\n",
    "    new_weights = []\n",
    "    new_bias = []\n",
    "    layer_index = len(a_layer)-1\n",
    "    delta = (a_layer[-1]-Y_train.T)/Y_train.shape[0]\n",
    "    new_weights.append(np.subtract(weights[layer_index-1] ,np.multiply((learningRate/iteration),np.matmul(delta,a_layer[layer_index-1].T))))\n",
    "    b = np.sum(delta,axis=1)\n",
    "    new_bias.append(np.subtract(bias[layer_index-1],np.multiply((learningRate/iteration),b.reshape(b.shape[0],1))))\n",
    "    layer_index-=1\n",
    "    while(layer_index>0):\n",
    "#         delta = np.matmul(weights[layer_index].T,delta)*sigmoid_der(z_layer[layer_index])\n",
    "        delta = np.matmul(weights[layer_index].T,delta)*reluder(z_layer[layer_index])\n",
    "#         delta = np.matmul(weights[layer_index].T,delta)*tanhder(z_layer[layer_index])\n",
    "        new_weights.append(np.subtract(weights[layer_index-1] ,np.multiply((learningRate/iteration),np.matmul(delta,a_layer[layer_index-1].T))))\n",
    "        b = np.sum(delta,axis=1)\n",
    "        new_bias.append(np.subtract(bias[layer_index-1],np.multiply((learningRate/iteration),b.reshape(b.shape[0],1))))\n",
    "        layer_index-=1\n",
    "    new_bias.reverse()\n",
    "    new_weights.reverse()\n",
    "    return (new_weights,new_bias)    \n",
    "k = batchSize\n",
    "l = X_train.shape[0]\n",
    "weights, bias = initialiseWeights(layer)\n",
    "error_value = []\n",
    "o = maxIteration\n",
    "batches = l/k\n",
    "for i in range(o):\n",
    "    start_index = int(k*(i%batches))\n",
    "    end_index = int(k*((i%batches)+1))\n",
    "    a_layer , z_layer = feedforward(weights,bias,X_train[start_index:end_index,:])\n",
    "    # error_value.append(error(a_layer[-1],Y_train[start_index:end_index,:]))\n",
    "    weights, bias = backpropagate(weights,bias,a_layer,z_layer,X_train[start_index:end_index,:],Y_train[start_index:end_index,:],np.sqrt(1))        \n",
    "    \n",
    "a_layer , z_layer = feedforward(weights,bias,X_test)\n",
    "a = np.array([ np.where(out==np.amax(out))[0][0] for out in a_layer[-1].T])\n",
    "np.savetxt(sys.argv[3],a)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
