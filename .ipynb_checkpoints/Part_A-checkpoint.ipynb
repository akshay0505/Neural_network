{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getcwd()+\"/Neural_data/Toy/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv.append(data_dir+\"train.csv\")\n",
    "sys.argv.append(data_dir+\"param.txt\")\n",
    "sys.argv.append(data_dir+\"weightfile.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(sys.argv[0],header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 2) (300,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train.iloc[:,:-1].values\n",
    "Y_train = train.iloc[:,-1].values\n",
    "print(X_train.shape,Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.05 500 50 [2, 50, 1]\n"
     ]
    }
   ],
   "source": [
    "with open(sys.argv[1]) as f:\n",
    "    param = f.read().split(\"\\n\")\n",
    "    learningType = int(param[0])\n",
    "    learningRate = float(param[1])\n",
    "    maxIteration = int(param[2])\n",
    "    batchSize = int(param[3])\n",
    "    layer = list(map(int,param[4].split(\" \")))\n",
    "    layer.insert(0,X_train.shape[1])\n",
    "    layer.append(1)\n",
    "print(learningType,learningRate,maxIteration,batchSize,layer)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialiseWeights(layer):\n",
    "    weights = []\n",
    "    bias = []\n",
    "    for i in range(1,len(layer)):\n",
    "        weights.append(np.zeros(layer[i-1]*layer[i]).reshape(layer[i],layer[i-1]))\n",
    "        bias.append(np.zeros(layer[i]).reshape(layer[i],1))\n",
    "        print(weights[i-1].shape,bias[i-1].shape)\n",
    "    return (weights,bias)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(weights,bias,X_train):\n",
    "    a_layer = []\n",
    "    z_layer = []\n",
    "    a_layer.append(X_train.T)\n",
    "    z_layer.append(0)\n",
    "    for i in range(0,len(layer)-1):\n",
    "        z_layer.append(np.matmul(weights[i],a_layer[i])+bias[i])\n",
    "        a_layer.append(sigmoid(z_layer[i+1]))\n",
    "    return (a_layer,z_layer)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 50, 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagate(weights,bias,a_layer,z_layer,X_train,Y_train):\n",
    "    new_weights = []\n",
    "    new_bias = []\n",
    "    layer_index = len(a_layer)-1\n",
    "    error_der = (a_layer[layer_index]-Y_train)/((1-a_layer[layer_index])*a_layer[layer_index]*X_train.shape[0])\n",
    "    s = sigmoid(z_layer[layer_index])\n",
    "    sigmaDer = (s*(1-s))\n",
    "    delta = error_der*sigmaDer\n",
    "    new_weights.append(np.subtract(weights[layer_index-1] ,np.multiply(learningRate,np.matmul(delta,a_layer[layer_index-1].T))))\n",
    "    b = np.sum(delta,axis=1)\n",
    "    new_bias.append(np.subtract(bias[layer_index-1],np.multiply(learningRate,b.reshape(b.shape[0],1))))\n",
    "    layer_index-=1\n",
    "    while(layer_index>0):\n",
    "        s = sigmoid(z_layer[layer_index])\n",
    "        sigmaDer = (s*(1-s))\n",
    "        delta = np.matmul(weights[layer_index].T,delta)*sigmaDer\n",
    "        new_weights.append(np.subtract(weights[layer_index-1] ,np.multiply(learningRate,np.matmul(delta,a_layer[layer_index-1].T))))\n",
    "        b = np.sum(delta,axis=1)\n",
    "        new_bias.append(np.subtract(bias[layer_index-1],np.multiply(learningRate,b.reshape(b.shape[0],1))))\n",
    "        layer_index-=1\n",
    "    new_bias.reverse()\n",
    "    new_weights.reverse()\n",
    "    return (new_weights,new_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 2) (50, 1)\n",
      "(1, 50) (1, 1)\n",
      "[-5.70561422e-06 -5.70561422e-06 -5.70561422e-06 -5.70561422e-06\n",
      " -5.70561422e-06 -5.70561422e-06 -5.70561422e-06 -5.70561422e-06\n",
      " -5.70561422e-06 -5.70561422e-06 -5.70561422e-06 -5.70561422e-06\n",
      " -5.70561422e-06 -5.70561422e-06 -5.70561422e-06 -5.70561422e-06\n",
      " -5.70561422e-06 -5.70561422e-06 -5.70561422e-06 -5.70561422e-06\n",
      " -5.70561422e-06 -5.70561422e-06 -5.70561422e-06 -5.70561422e-06\n",
      " -5.70561422e-06 -5.70561422e-06 -5.70561422e-06 -5.70561422e-06\n",
      " -5.70561422e-06 -5.70561422e-06 -5.70561422e-06 -5.70561422e-06\n",
      " -5.70561422e-06 -5.70561422e-06 -5.70561422e-06 -5.70561422e-06\n",
      " -5.70561422e-06 -5.70561422e-06 -5.70561422e-06 -5.70561422e-06\n",
      " -5.70561422e-06 -5.70561422e-06 -5.70561422e-06 -5.70561422e-06\n",
      " -5.70561422e-06 -5.70561422e-06 -5.70561422e-06 -5.70561422e-06\n",
      " -5.70561422e-06 -5.70561422e-06]\n",
      "[-0.00172714]\n",
      "errr\n",
      "[-1.57902612e-06 -1.42602527e-05 -1.57902612e-06 -1.42602527e-05\n",
      " -1.57902612e-06 -1.42602527e-05 -1.57902612e-06 -1.42602527e-05\n",
      " -1.57902612e-06 -1.42602527e-05 -1.57902612e-06 -1.42602527e-05\n",
      " -1.57902612e-06 -1.42602527e-05 -1.57902612e-06 -1.42602527e-05\n",
      " -1.57902612e-06 -1.42602527e-05 -1.57902612e-06 -1.42602527e-05\n",
      " -1.57902612e-06 -1.42602527e-05 -1.57902612e-06 -1.42602527e-05\n",
      " -1.57902612e-06 -1.42602527e-05 -1.57902612e-06 -1.42602527e-05\n",
      " -1.57902612e-06 -1.42602527e-05 -1.57902612e-06 -1.42602527e-05\n",
      " -1.57902612e-06 -1.42602527e-05 -1.57902612e-06 -1.42602527e-05\n",
      " -1.57902612e-06 -1.42602527e-05 -1.57902612e-06 -1.42602527e-05\n",
      " -1.57902612e-06 -1.42602527e-05 -1.57902612e-06 -1.42602527e-05\n",
      " -1.57902612e-06 -1.42602527e-05 -1.57902612e-06 -1.42602527e-05\n",
      " -1.57902612e-06 -1.42602527e-05 -1.57902612e-06 -1.42602527e-05\n",
      " -1.57902612e-06 -1.42602527e-05 -1.57902612e-06 -1.42602527e-05\n",
      " -1.57902612e-06 -1.42602527e-05 -1.57902612e-06 -1.42602527e-05\n",
      " -1.57902612e-06 -1.42602527e-05 -1.57902612e-06 -1.42602527e-05\n",
      " -1.57902612e-06 -1.42602527e-05 -1.57902612e-06 -1.42602527e-05\n",
      " -1.57902612e-06 -1.42602527e-05 -1.57902612e-06 -1.42602527e-05\n",
      " -1.57902612e-06 -1.42602527e-05 -1.57902612e-06 -1.42602527e-05\n",
      " -1.57902612e-06 -1.42602527e-05 -1.57902612e-06 -1.42602527e-05\n",
      " -1.57902612e-06 -1.42602527e-05 -1.57902612e-06 -1.42602527e-05\n",
      " -1.57902612e-06 -1.42602527e-05 -1.57902612e-06 -1.42602527e-05\n",
      " -1.57902612e-06 -1.42602527e-05 -1.57902612e-06 -1.42602527e-05\n",
      " -1.57902612e-06 -1.42602527e-05 -1.57902612e-06 -1.42602527e-05\n",
      " -1.57902612e-06 -1.42602527e-05 -1.57902612e-06 -1.42602527e-05]\n",
      "[-0.00086353 -0.00086353 -0.00086353 -0.00086353 -0.00086353 -0.00086353\n",
      " -0.00086353 -0.00086353 -0.00086353 -0.00086353 -0.00086353 -0.00086353\n",
      " -0.00086353 -0.00086353 -0.00086353 -0.00086353 -0.00086353 -0.00086353\n",
      " -0.00086353 -0.00086353 -0.00086353 -0.00086353 -0.00086353 -0.00086353\n",
      " -0.00086353 -0.00086353 -0.00086353 -0.00086353 -0.00086353 -0.00086353\n",
      " -0.00086353 -0.00086353 -0.00086353 -0.00086353 -0.00086353 -0.00086353\n",
      " -0.00086353 -0.00086353 -0.00086353 -0.00086353 -0.00086353 -0.00086353\n",
      " -0.00086353 -0.00086353 -0.00086353 -0.00086353 -0.00086353 -0.00086353\n",
      " -0.00086353 -0.00086353]\n"
     ]
    }
   ],
   "source": [
    "k = batchSize\n",
    "l = X_train.shape[0]\n",
    "weights, bias = initialiseWeights(layer)\n",
    "error = []\n",
    "maxIteration = 10\n",
    "for i in range(maxIteration):\n",
    "    start_index = int((k)*(i%6))\n",
    "    end_index = int((k)*((i%6)+1))\n",
    "    a_layer , z_layer = feedforward(weights,bias,X_train[start_index:end_index,:])\n",
    "    weights, bias = backpropagate(weights,bias,a_layer,z_layer,X_train[start_index:end_index,:],Y_train[start_index:end_index])\n",
    "    if(i+1==10):\n",
    "        for k in range(len(bias)):\n",
    "            print(bias[k].flatten())\n",
    "        print(\"errr\")\n",
    "        for k in range(len(weights)):\n",
    "            print(weights[k].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([])\n",
    "for i in range(len(bias)):\n",
    "    a = np.concatenate((a,bias[i].flatten(),weights[i].flatten('F')))\n",
    "np.savetxt(\"we.txt\",a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_layer , z_layer = feedforward(weights,bias,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_layer[2][a_layer[2]>0.5]=1\n",
    "a_layer[2][a_layer[2]<0.5]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_layer[2].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7f90efa2f9fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ma_layer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'actual'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    390\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    391\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrays must all be same length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "pd.DataFrame({'pred':a_layer[2].tolist(),'actual':Y_train.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sum() got multiple values for argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b45890c5c2d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_layer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: sum() got multiple values for argument 'axis'"
     ]
    }
   ],
   "source": [
    "np.sum(a_layer[2],Y_train,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagate(weights,bias,a_layer,z_layer,X_train,Y_train):\n",
    "    new_weights = []\n",
    "    new_bias = []\n",
    "    error_der = (a_layer[2]-Y_train)/((1-a_layer[2])*a_layer[2]*X_train.shape[0])\n",
    "    s = sigmoid(z_layer[2])\n",
    "    sigmaDer = (s*(1-s))\n",
    "    deltaL = error_der*sigmaDer\n",
    "    new_weights.append(np.subtract(weights[1] ,np.multiply(learningRate,np.matmul(deltaL,a_layer[1].T))))\n",
    "    b = np.sum(deltaL,axis=1)\n",
    "    new_bias.append(np.subtract(bias[1],np.multiply(learningRate,b.reshape(b.shape[0],1))))\n",
    "    s = sigmoid(z_layer[1])\n",
    "    sigmaDer = (s*(1-s))\n",
    "    deltal3 = np.matmul(weights[1].T,deltaL)*sigmaDer\n",
    "    new_weights.append(np.subtract(weights[0] ,np.multiply(learningRate,np.matmul(deltal3,a_layer[0].T))))\n",
    "    b = np.sum(deltal3,axis=1)\n",
    "    new_bias.append(np.subtract(bias[0],np.multiply(learningRate,b.reshape(b.shape[0],1))))\n",
    "    new_bias.reverse()\n",
    "    new_weights.reverse()\n",
    "    return (new_weights,new_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k = batchSize\n",
    "l = X_train.shape[0]\n",
    "maxIteration =30\n",
    "weights, bias = initialiseWeights(layer)\n",
    "error = []\n",
    "for i in range(maxIteration):\n",
    "    start_index = int((k)*(i%6))\n",
    "    end_index = int((k)*((i%6)+1))\n",
    "    a_layer , z_layer = feedforward(weights,bias,X_train[start_index:end_index,:])\n",
    "    weights, bias = backpropagate(weights,bias,a_layer,z_layer,X_train[start_index:end_index,:],Y_train[start_index:end_index])\n",
    "# a_layer , z_layer = feedforward(weights,bias,X_train)\n",
    "# error.append(np.linalg.norm(np.subtract(a_layer[2],Y_train))/300)   \n",
    "for i in range(len(bias)):\n",
    "    print(bias[i].flatten())\n",
    "print(\"errr\")\n",
    "for i in range(len(weights)):\n",
    "    print(weights[i].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, bias = initialiseWeights(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "k = batchSize\n",
    "l = X_train.shape[0]\n",
    "maxIteration =1\n",
    "weights, bias = initialiseWeights(layer)\n",
    "error = []\n",
    "for j in range(maxIteration):\n",
    "#     print(j,end=\"\\r\",flush=True)\n",
    "    for i in range(int(l/k)):\n",
    "        start_index = int((k)*i)\n",
    "        end_index = int((k)*(i+1))\n",
    "        a_layer , z_layer = feedforward(weights,bias,X_train[start_index:end_index,:])\n",
    "        weights, bias = backpropagate(weights,bias,a_layer,z_layer,X_train[start_index:end_index,:],Y_train[start_index:end_index])\n",
    "#         for k in range(len(bias)):\n",
    "#             print(bias[k].flatten(),weights[k].flatten())\n",
    "#         print(\"hi this is akshay\\n\\n\\n\")\n",
    "    a_layer , z_layer = feedforward(weights,bias,X_train)\n",
    "    error.append(np.linalg.norm(np.subtract(a_layer[2],Y_train))/300)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(error)),error)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_layer , z_layer = feedforward(weights,bias,X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_layer[2]+Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, bias = initialiseWeights(layer)\n",
    "a_layer , z_layer = feedforward(weights,bias,X_train[0:50])\n",
    "weights, bias = backpropagate(weights,bias,a_layer,z_layer,X_train[0:50],Y_train[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(bias)):\n",
    "    print(bias[i].flatten())\n",
    "print(\"errr\")\n",
    "for i in range(len(weights)):\n",
    "    print(weights[i].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am = [10 , 20 ,30]\n",
    "40 in am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weights[3].shape,deltaL.shape,a_layer[3].T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights = []\n",
    "new_bias = []\n",
    "error_der = (a_layer[2]-Y_train)/((1-a_layer[2])*a_layer[2]*X_train.shape[0])\n",
    "s = sigmoid(z_layer[2])\n",
    "sigmaDer = (s*(1-s))\n",
    "deltaL = error_der*sigmaDer\n",
    "print(deltaL.shape)\n",
    "new_weights.append(np.subtract(weights[1] ,np.multiply(learningRate,np.matmul(deltaL,a_layer[1].T))))\n",
    "b = np.sum(deltaL,axis=1)\n",
    "new_bias.append(b.reshape(b.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(new_weights[-1])\n",
    "s = sigmoid(z_layer[1])\n",
    "sigmaDer = (s*(1-s))\n",
    "deltal3 = np.matmul(weights[1].T,deltaL)*sigmaDer\n",
    "new_weights.append(np.subtract(weights[0] ,np.multiply(learningRate,np.matmul(deltal3,a_layer[0].T))))\n",
    "b = np.sum(deltal3,axis=1)\n",
    "new_bias.append(b.reshape(b.shape[0],1))\n",
    "# print(new_weights[0].shape,new_weights[1].shape)\n",
    "# print(np.sum(deltaL),deltal3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bias.reverse()\n",
    "new_weights.reverse()\n",
    "print(new_bias,\"\\n\",new_weights)\n",
    "weights = new_weights\n",
    "bias = new_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sigmoid(z_layer[1])\n",
    "sigmaDer = (s*(1-s))\n",
    "deltal3 = np.matmul(weights[1].T,deltaL)*sigmaDer\n",
    "print(weights[1].shape,deltaL.shape,sigmaDer.shape)\n",
    "new_bias.append(np.sum(deltal3,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matmul(weights[1].T,deltaL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights = []\n",
    "new_bias = []\n",
    "error_der = (a_layer[4]-Y_train)/((1-a_layer[4])*a_layer[4]*X_train.shape[0])\n",
    "s = sigmoid(z_layer[4])\n",
    "sigmaDer = (s*(1-s))\n",
    "deltaL = error_der*sigmaDer\n",
    "print(deltaL.shape)\n",
    "new_weights.append(np.subtract(weights[3] ,np.multiply(learningRate,np.matmul(deltaL,a_layer[3].T))))\n",
    "print(new_weights[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sigmoid(z_layer[3])\n",
    "sigmaDer = (s*(1-s))\n",
    "deltal3 = np.matmul(weights[3].T,deltaL)*sigmaDer\n",
    "new_weights.append(np.subtract(weights[2] ,np.multiply(learningRate,np.matmul(deltal3,a_layer[2].T))))\n",
    "print(new_weights[-1])\n",
    "# print(weights[2].shape,deltal3.shape,a_layer[2].T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sigmoid(z_layer[2])\n",
    "sigmaDer = (s*(1-s))\n",
    "deltal2 = np.matmul(weights[2].T,deltal3)*sigmaDer\n",
    "new_weights.append(np.subtract(weights[1] ,np.multiply(learningRate,np.matmul(deltal2,a_layer[1].T))))\n",
    "print(new_weights[-1])\n",
    "# print(weights[2].shape,deltal3.shape,a_layer[2].T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sigmoid(z_layer[1])\n",
    "sigmaDer = (s*(1-s))\n",
    "deltal1 = np.matmul(weights[1].T,deltal2)*sigmaDer\n",
    "new_weights.append(np.subtract(weights[0] ,np.multiply(learningRate,np.matmul(deltal1,a_layer[0].T))))\n",
    "print(new_weights[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltal3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.negative(deltaL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = X_train.T\n",
    "z1 = np.matmul(weights[0],y0)+bias[0]\n",
    "y1 = sigmoid(z1)\n",
    "z2 = np.matmul(weights[1],y1)+bias[1]\n",
    "y2 = sigmoid(z2)\n",
    "z3 = np.matmul(weights[2],y2)+bias[2]\n",
    "y3 = sigmoid(z3)\n",
    "z4 = np.matmul(weights[3],y3)+bias[3]\n",
    "y4 = sigmoid(z4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y0.shape,y1.shape,y2.shape,y3.shape,y4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
